{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "import pandas as pd\n",
    "import os\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sys import platform\n",
    "from sklearn.model_selection import train_test_split, GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['video_id','start_time','mid_ts','label','audio','vggish']\n",
    "\n",
    "d=np.load(f'./resources/working_data/vocal_only_data_with_vggish.npy',allow_pickle=True)\n",
    "df = pd.DataFrame(d,columns=cols)\n",
    "\n",
    "lut = pd.read_csv(f'../dataset/lookup.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.merge(lut[['video_id','band_name']],on='video_id')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df=df[['label','audio','band_name']]\n",
    "mapping=[]\n",
    "for index,row in feature_df.iterrows():\n",
    "    if row['label'] == 'clean':\n",
    "        mapping.append(0)\n",
    "    if row['label'] == 'highfry':\n",
    "        mapping.append(1)\n",
    "    if row['label'] == 'layered':\n",
    "        mapping.append(1)\n",
    "    if row['label'] == 'lowfry':\n",
    "        mapping.append(1)\n",
    "    if row['label'] == 'midfry':\n",
    "        mapping.append(1)\n",
    "    if row['label'] == 'no_vocals':\n",
    "        mapping.append(2)\n",
    "\n",
    "feature_df.insert(3,'label_mapped',mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Undersampling the master data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "undersample = RandomUnderSampler(sampling_strategy={0:2462,1:3000,2:3000},random_state=0)\n",
    "X = feature_df[['audio','band_name']].to_numpy()\n",
    "y=feature_df['label_mapped'].to_numpy()\n",
    "X_under, y_under = undersample.fit_resample(X, y)\n",
    "\n",
    "band_names = X_under[:,1]\n",
    "X_under=X_under[:,0]#.reshape(-1,1).flatten()\n",
    "y_under=y_under"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=pd.DataFrame()\n",
    "d['y_under'] = y_under\n",
    "d['blah'] = 1\n",
    "\n",
    "print(d.groupby('y_under')['blah'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating train-test-validation split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gss = GroupShuffleSplit(n_splits=5, train_size=.7, random_state=42)\n",
    "train,test = next(gss.split(X_under, y_under, band_names))\n",
    "# for train_idx,test_idx in gss.split(X_under, y_under, band_names): \n",
    "#     print(train_idx,test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_under[train]\n",
    "X_test1 = X_under[test]\n",
    "\n",
    "y_train = y_under[train]\n",
    "y_test1 = y_under[test]\n",
    "\n",
    "X_test,X_valid,y_test,y_valid = train_test_split(X_test1, y_test1,test_size=0.5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)\n",
    "y_valid_hot = to_categorical(y_valid)\n",
    "\n",
    "X_train,y_train=shuffle(X_train,y_train_hot)\n",
    "X_test,y_test=shuffle(X_test,y_test_hot)\n",
    "X_valid,y_valid=shuffle(X_valid,y_valid_hot)\n",
    "\n",
    "np.save(f'./resources/working_data/x_train-rawaudio.npy', X_train)\n",
    "np.save(f'./resources/working_data/x_test-rawaudio.npy', X_test)\n",
    "np.save(f'./resources/working_data/x_valid-rawaudio.npy', X_valid)\n",
    "\n",
    "np.save(f'./resources/working_data/y_train-rawaudio.npy', y_train)\n",
    "np.save(f'./resources/working_data/y_test-rawaudio.npy', y_test)\n",
    "np.save(f'./resources/working_data/y_valid-rawaudio.npy', y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGGish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=np.load(f'./resources/working_data/vocal_only_data_with_vggish.npy',allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d[:,5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.concatenate(d[:,5]).reshape(33820,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df=df[['label','vggish','band_name']]\n",
    "mapping=[]\n",
    "for index,row in feature_df.iterrows():\n",
    "    if row['label'] == 'clean':\n",
    "        mapping.append(0)\n",
    "    if row['label'] == 'highfry':\n",
    "        mapping.append(1)\n",
    "    if row['label'] == 'layered':\n",
    "        mapping.append(1)\n",
    "    if row['label'] == 'lowfry':\n",
    "        mapping.append(1)\n",
    "    if row['label'] == 'midfry':\n",
    "        mapping.append(1)\n",
    "    if row['label'] == 'no_vocals':\n",
    "        mapping.append(2)\n",
    "\n",
    "feature_df.insert(3,'label_mapped',mapping)\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "undersample = RandomUnderSampler(sampling_strategy={0:2462,1:3000,2:3000},random_state=0)\n",
    "X = feature_df[['vggish','band_name']].to_numpy()\n",
    "y=feature_df['label_mapped'].to_numpy()\n",
    "X_under, y_under = undersample.fit_resample(X, y)\n",
    "\n",
    "band_names = X_under[:,1]\n",
    "X_under=X_under[:,0]#.reshape(-1,1).flatten()\n",
    "X_under=np.concatenate(X_under).reshape(X_under.shape[0],128)\n",
    "\n",
    "y_under=y_under\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=5, train_size=.7, random_state=42)\n",
    "train,test = next(gss.split(X_under, y_under, band_names))\n",
    "# for train_idx,test_idx in gss.split(X_under, y_under, band_names): \n",
    "#     print(train_idx,test_idx)\n",
    "\n",
    "X_train = X_under[train]\n",
    "X_test1 = X_under[test]\n",
    "\n",
    "y_train = y_under[train]\n",
    "y_test1 = y_under[test]\n",
    "\n",
    "X_test,X_valid,y_test,y_valid = train_test_split(X_test1, y_test1,test_size=0.5,random_state=42)\n",
    "\n",
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)\n",
    "y_valid_hot = to_categorical(y_valid)\n",
    "\n",
    "X_train,y_train=shuffle(X_train,y_train_hot)\n",
    "X_test,y_test=shuffle(X_test,y_test_hot)\n",
    "X_valid,y_valid=shuffle(X_valid,y_valid_hot)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'./resources/working_data/x_train-vggish.npy', X_train)\n",
    "np.save(f'./resources/working_data/x_test-vggish.npy', X_test)\n",
    "np.save(f'./resources/working_data/x_valid-vggish.npy', X_valid)\n",
    "\n",
    "np.save(f'./resources/working_data/y_train-vggish.npy', y_train)\n",
    "np.save(f'./resources/working_data/y_test-vggish.npy', y_test)\n",
    "np.save(f'./resources/working_data/y_valid-vggish.npy', y_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['video_id', 'start_time', 'mid_ts', 'label', 'average_zcr',\n",
    "       'zcr_stddev', 'mfcc1_mean', 'mfcc2_mean', 'mfcc3_mean',\n",
    "       'mfcc4_mean', 'mfcc5_mean', 'mfcc6_mean', 'mfcc7_mean', 'mfcc8_mean',\n",
    "       'mfcc9_mean', 'mfcc10_mean', 'mfcc11_mean', 'mfcc12_mean',\n",
    "       'mfcc13_mean', 'mfcc1_std', 'mfcc2_std', 'mfcc3_std', 'mfcc4_std',\n",
    "       'mfcc5_std', 'mfcc6_std', 'mfcc7_std', 'mfcc8_std', 'mfcc9_std',\n",
    "       'mfcc10_std', 'mfcc11_std', 'mfcc12_std', 'mfcc13_std',\n",
    "       'delta_mfcc1_mean', 'delta_mfcc2_mean', 'delta_mfcc3_mean',\n",
    "       'delta_mfcc4_mean', 'delta_mfcc5_mean', 'delta_mfcc6_mean',\n",
    "       'delta_mfcc7_mean', 'delta_mfcc8_mean', 'delta_mfcc9_mean',\n",
    "       'delta_mfcc10_mean', 'delta_mfcc11_mean', 'delta_mfcc12_mean',\n",
    "       'delta_mfcc13_mean', 'delta_mfcc1_std', 'delta_mfcc2_std',\n",
    "       'delta_mfcc3_std', 'delta_mfcc4_std', 'delta_mfcc5_std',\n",
    "       'delta_mfcc6_std', 'delta_mfcc7_std', 'delta_mfcc8_std',\n",
    "       'delta_mfcc9_std', 'delta_mfcc10_std', 'delta_mfcc11_std',\n",
    "       'delta_mfcc12_std', 'delta_mfcc13_std',\n",
    "       'centroid_mean','centroid_std',\n",
    "       'contrast_mean','contrast_std',\n",
    "       'flatness_mean','flatness_std',\n",
    "       'rolloff_mean','rolloff_std','rms_mean','rms_std','vggish']\n",
    "\n",
    "d=np.load(f'./resources/working_data/vocal_only_features.npy',allow_pickle=True)\n",
    "df = pd.DataFrame(d,columns=cols)\n",
    "\n",
    "lut = pd.read_csv(f'../dataset/lookup.csv')\n",
    "\n",
    "df=df.merge(lut[['video_id','band_name']],on='video_id')\n",
    "df\n",
    "\n",
    "feature_df=df[['label', 'band_name', 'average_zcr',\n",
    "       'zcr_stddev', 'mfcc1_mean', 'mfcc2_mean', 'mfcc3_mean',\n",
    "       'mfcc4_mean', 'mfcc5_mean', 'mfcc6_mean', 'mfcc7_mean', 'mfcc8_mean',\n",
    "       'mfcc9_mean', 'mfcc10_mean', 'mfcc11_mean', 'mfcc12_mean',\n",
    "       'mfcc13_mean', 'mfcc1_std', 'mfcc2_std', 'mfcc3_std', 'mfcc4_std',\n",
    "       'mfcc5_std', 'mfcc6_std', 'mfcc7_std', 'mfcc8_std', 'mfcc9_std',\n",
    "       'mfcc10_std', 'mfcc11_std', 'mfcc12_std', 'mfcc13_std',\n",
    "       'delta_mfcc1_mean', 'delta_mfcc2_mean', 'delta_mfcc3_mean',\n",
    "       'delta_mfcc4_mean', 'delta_mfcc5_mean', 'delta_mfcc6_mean',\n",
    "       'delta_mfcc7_mean', 'delta_mfcc8_mean', 'delta_mfcc9_mean',\n",
    "       'delta_mfcc10_mean', 'delta_mfcc11_mean', 'delta_mfcc12_mean',\n",
    "       'delta_mfcc13_mean', 'delta_mfcc1_std', 'delta_mfcc2_std',\n",
    "       'delta_mfcc3_std', 'delta_mfcc4_std', 'delta_mfcc5_std',\n",
    "       'delta_mfcc6_std', 'delta_mfcc7_std', 'delta_mfcc8_std',\n",
    "       'delta_mfcc9_std', 'delta_mfcc10_std', 'delta_mfcc11_std',\n",
    "       'delta_mfcc12_std', 'delta_mfcc13_std',\n",
    "       'centroid_mean','centroid_std',\n",
    "       'contrast_mean','contrast_std',\n",
    "       'flatness_mean','flatness_std',\n",
    "       'rolloff_mean','rolloff_std','rms_mean','rms_std']]\n",
    "mapping=[]\n",
    "for index,row in feature_df.iterrows():\n",
    "    if row['label'] == 'clean':\n",
    "        mapping.append(0)\n",
    "    if row['label'] == 'highfry':\n",
    "        mapping.append(1)\n",
    "    if row['label'] == 'layered':\n",
    "        mapping.append(1)\n",
    "    if row['label'] == 'lowfry':\n",
    "        mapping.append(1)\n",
    "    if row['label'] == 'midfry':\n",
    "        mapping.append(1)\n",
    "    if row['label'] == 'no_vocals':\n",
    "        mapping.append(2)\n",
    "\n",
    "feature_df.insert(3,'label_mapped',mapping)\n",
    "\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "undersample = RandomUnderSampler(sampling_strategy={0:2462,1:3000,2:3000},random_state=0)\n",
    "X = feature_df[['average_zcr',\n",
    "       'zcr_stddev', 'mfcc1_mean', 'mfcc2_mean', 'mfcc3_mean',\n",
    "       'mfcc4_mean', 'mfcc5_mean', 'mfcc6_mean', 'mfcc7_mean', 'mfcc8_mean',\n",
    "       'mfcc9_mean', 'mfcc10_mean', 'mfcc11_mean', 'mfcc12_mean',\n",
    "       'mfcc13_mean', 'mfcc1_std', 'mfcc2_std', 'mfcc3_std', 'mfcc4_std',\n",
    "       'mfcc5_std', 'mfcc6_std', 'mfcc7_std', 'mfcc8_std', 'mfcc9_std',\n",
    "       'mfcc10_std', 'mfcc11_std', 'mfcc12_std', 'mfcc13_std',\n",
    "       'delta_mfcc1_mean', 'delta_mfcc2_mean', 'delta_mfcc3_mean',\n",
    "       'delta_mfcc4_mean', 'delta_mfcc5_mean', 'delta_mfcc6_mean',\n",
    "       'delta_mfcc7_mean', 'delta_mfcc8_mean', 'delta_mfcc9_mean',\n",
    "       'delta_mfcc10_mean', 'delta_mfcc11_mean', 'delta_mfcc12_mean',\n",
    "       'delta_mfcc13_mean', 'delta_mfcc1_std', 'delta_mfcc2_std',\n",
    "       'delta_mfcc3_std', 'delta_mfcc4_std', 'delta_mfcc5_std',\n",
    "       'delta_mfcc6_std', 'delta_mfcc7_std', 'delta_mfcc8_std',\n",
    "       'delta_mfcc9_std', 'delta_mfcc10_std', 'delta_mfcc11_std',\n",
    "       'delta_mfcc12_std', 'delta_mfcc13_std',\n",
    "       'centroid_mean','centroid_std',\n",
    "       'contrast_mean','contrast_std',\n",
    "       'flatness_mean','flatness_std',\n",
    "       'rolloff_mean','rolloff_std','rms_mean','rms_std','band_name']].to_numpy()\n",
    "y=feature_df['label_mapped'].to_numpy()\n",
    "X_under, y_under = undersample.fit_resample(X, y)\n",
    "\n",
    "band_names = X_under[:,-1]\n",
    "X_under=X_under[:,:-1]#.reshape(-1,1).flatten()\n",
    "y_under=y_under\n",
    "\n",
    "gss = GroupShuffleSplit(n_splits=5, train_size=.7, random_state=42)\n",
    "train,test = next(gss.split(X_under, y_under, band_names))\n",
    "# for train_idx,test_idx in gss.split(X_under, y_under, band_names): \n",
    "#     print(train_idx,test_idx)\n",
    "\n",
    "X_train = X_under[train]\n",
    "X_test1 = X_under[test]\n",
    "\n",
    "y_train = y_under[train]\n",
    "y_test1 = y_under[test]\n",
    "\n",
    "X_test,X_valid,y_test,y_valid = train_test_split(X_test1, y_test1,test_size=0.5,random_state=42)\n",
    "\n",
    "y_train_hot = to_categorical(y_train)\n",
    "y_test_hot = to_categorical(y_test)\n",
    "y_valid_hot = to_categorical(y_valid)\n",
    "\n",
    "X_train,y_train=shuffle(X_train,y_train_hot)\n",
    "X_test,y_test=shuffle(X_test,y_test_hot)\n",
    "X_valid,y_valid=shuffle(X_valid,y_valid_hot)\n",
    "\n",
    "np.save(f'./resources/working_data/x_train-features_unnormalized.npy', X_train)\n",
    "np.save(f'./resources/working_data/x_test-features_unnormalized.npy', X_test)\n",
    "np.save(f'./resources/working_data/x_valid-features_unnormalized.npy', X_valid)\n",
    "\n",
    "np.save(f'./resources/working_data/y_train-features_unnormalized.npy', y_train)\n",
    "np.save(f'./resources/working_data/y_test-features_unnormalized.npy', y_test)\n",
    "np.save(f'./resources/working_data/y_valid-features_unnormalized.npy', y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
